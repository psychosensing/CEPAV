{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce48acc5-0fbe-4d4a-8367-6bda026c217c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from datetime import datetime, time\n",
    "# import matplotlib.pyplot as plt\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "path = '/home/ubuntu/eSportData/jupyter-data/VU_AMS/s2'\n",
    "path_out = '/home/ubuntu/eSportData/jupyter-data/VU_AMS/s2_output'\n",
    "path_tx = '/home/ubuntu/eSportData/jupyter-data/beatscope/Pliki/S2'\n",
    "path_acc = '/home/ubuntu/eSportData/jupyter-data/akcelerometry/S2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd69ba3a-90eb-4748-8397-f77743024379",
   "metadata": {},
   "outputs": [],
   "source": [
    "rejected = []\n",
    "output_filename = \"output.txt\"\n",
    "rejected_list = 'rejected.txt'\n",
    "outputs = []\n",
    "output_errors_path = '/home/ubuntu/eSportData/jupyter-data/VU_AMS/error_s2.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03dc85c5-633d-4e49-b932-00330b656b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_time_from_file(filename):\n",
    "    \"\"\"\n",
    "    function to read time from vuams files\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(filename, 'r') as file:\n",
    "            next(file)\n",
    "            second_row = next(file).strip()\n",
    "            parts = second_row.split(\"/\")\n",
    "            return str(parts[1])\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File '{filename}' not found.\")\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "def merge_vs_tx(start_markers, vuams, beat, columns, da_df, tls, keys):\n",
    "    \"\"\"\n",
    "    function to merge vuams df with beatscope files. All files have the same number of rows after adding the time column from vuams to each beatscope file.\n",
    "    input : \n",
    "        start_markers: information about indexes where vuams markers start for the whole procedure\n",
    "        vuams: vuams df with the first measurement merged with beatscope (to be able to freely iterate over the whole set of needed columns)\n",
    "        columns: vuams and beatscope columns needed to assemble the dataframe\n",
    "        da_df: vuams df before merging with the first beatscope\n",
    "        tls: list with all beatscope dfs\n",
    "        keys: dictionary of markers, keys -> vuams markers, values -> beatscope markers. All as strings\n",
    "    output:\n",
    "        merged vuams df with all beatscope files\n",
    "    \"\"\"\n",
    "    for markers in start_markers[1:]: # skipping the first marker because the first beatscope file is already added to vuams using a regular merge\n",
    "        \n",
    "        da_sync_value = str(da_df.loc[markers, 'marker']) # and vice versa - marker value corresponding to the index\n",
    "        print(da_sync_value)\n",
    "        which_index = start_markers.index(markers) # iteration information\n",
    "        try:\n",
    "            tx_sync_idx_m1 = tls[which_index].index[tls[which_index]['marker_tx'] == keys[da_sync_value]][0] # finds in the given beatscope from the list of beatscopes (tls) the index when the marker starts (m10, m11, etc.)\n",
    "            print(tx_sync_idx_m1)\n",
    "            rows_diff = tx_sync_idx_m1 - markers # row difference between bs and vuams\n",
    "            print(rows_diff)\n",
    "        except:\n",
    "            tx_sync_idx_m1 = False\n",
    "        if tx_sync_idx_m1 != False:\n",
    "            if markers != start_markers[-1]:\n",
    "                for row in range(markers,markers + 270000): # iterates only from the index when the vuams marker starts and for 4 minutes (i.e., the duration of each measurement except the first and last one)\n",
    "                                                            # + 30 seconds buffer\n",
    "                    for value_idx in range(len(vuams[row])):\n",
    "                        if vuams[markers][value_idx] == 215: # adds to the specified vuams columns information from the beatscope after accounting for the row difference in data frames\n",
    "                            try:\n",
    "                                vuams[row][7] = beat[1][row+rows_diff][1]\n",
    "                                vuams[row][8] = beat[1][row+rows_diff][2]\n",
    "                                vuams[row][9] = beat[1][row+rows_diff][3]\n",
    "                                vuams[row][10] = beat[1][row+rows_diff][4]\n",
    "                                vuams[row][11] = beat[1][row+rows_diff][5]\n",
    "                                vuams[row][12] = beat[1][row+rows_diff][6]\n",
    "                                vuams[row][13] = beat[1][row+rows_diff][7]\n",
    "                                vuams[row][14] = beat[1][row+rows_diff][8]\n",
    "                                vuams[row][15] = beat[1][row+rows_diff][9]\n",
    "                                vuams[row][16] = beat[1][row+rows_diff][10]\n",
    "                                vuams[row][17] = beat[1][row+rows_diff][11]\n",
    "                            except:\n",
    "                                pass\n",
    "                        \n",
    "                        elif vuams[markers][value_idx] == 225:\n",
    "                            try:\n",
    "                                vuams[row][7] = beat[2][row+rows_diff][1]\n",
    "                                vuams[row][8] = beat[2][row+rows_diff][2]\n",
    "                                vuams[row][9] = beat[2][row+rows_diff][3]\n",
    "                                vuams[row][10] = beat[2][row+rows_diff][4]\n",
    "                                vuams[row][11] = beat[2][row+rows_diff][5]\n",
    "                                vuams[row][12] = beat[2][row+rows_diff][6]\n",
    "                                vuams[row][13] = beat[2][row+rows_diff][7]\n",
    "                                vuams[row][14] = beat[2][row+rows_diff][8]\n",
    "                                vuams[row][15] = beat[2][row+rows_diff][9]\n",
    "                                vuams[row][16] = beat[2][row+rows_diff][10]\n",
    "                                vuams[row][17] = beat[2][row+rows_diff][11]\n",
    "                            except:\n",
    "                                pass\n",
    "                            \n",
    "                        elif vuams[markers][value_idx] == 235:\n",
    "                            try:\n",
    "                                vuams[row][7] = beat[3][row+rows_diff][1]\n",
    "                                vuams[row][8] = beat[3][row+rows_diff][2]\n",
    "                                vuams[row][9] = beat[3][row+rows_diff][3]\n",
    "                                vuams[row][10] = beat[3][row+rows_diff][4]\n",
    "                                vuams[row][11] = beat[3][row+rows_diff][5]\n",
    "                                vuams[row][12] = beat[3][row+rows_diff][6]\n",
    "                                vuams[row][13] = beat[3][row+rows_diff][7]\n",
    "                                vuams[row][14] = beat[3][row+rows_diff][8]\n",
    "                                vuams[row][15] = beat[3][row+rows_diff][9]\n",
    "                                vuams[row][16] = beat[3][row+rows_diff][10]\n",
    "                                vuams[row][17] = beat[3][row+rows_diff][11]\n",
    "                            except:\n",
    "                                pass\n",
    "                        elif vuams[markers][value_idx] == 245:\n",
    "                            try:\n",
    "                            # for i_4 in range(row, len(da_bc_list)):\n",
    "                                vuams[row][7] = beat[4][row+rows_diff][1]\n",
    "                                vuams[row][8] = beat[4][row+rows_diff][2]\n",
    "                                vuams[row][9] = beat[4][row+rows_diff][3]\n",
    "                                vuams[row][10] = beat[4][row+rows_diff][4]\n",
    "                                vuams[row][11] = beat[4][row+rows_diff][5]\n",
    "                                vuams[row][12] = beat[4][row+rows_diff][6]\n",
    "                                vuams[row][13] = beat[4][row+rows_diff][7]\n",
    "                                vuams[row][14] = beat[4][row+rows_diff][8]\n",
    "                                vuams[row][15] = beat[4][row+rows_diff][9]\n",
    "                                vuams[row][16] = beat[4][row+rows_diff][10]\n",
    "                                vuams[row][17] = beat[4][row+rows_diff][11]\n",
    "                            except:\n",
    "                                pass\n",
    "                        elif vuams[markers][value_idx] == 255:\n",
    "                            try:\n",
    "                        \n",
    "                                vuams[row][7] = beat[5][row+rows_diff][1]\n",
    "                                vuams[row][8] = beat[5][row+rows_diff][2]\n",
    "                                vuams[row][9] = beat[5][row+rows_diff][3]\n",
    "                                vuams[row][10] = beat[5][row+rows_diff][4]\n",
    "                                vuams[row][11] = beat[5][row+rows_diff][5]\n",
    "                                vuams[row][12] = beat[5][row+rows_diff][6]\n",
    "                                vuams[row][13] = beat[5][row+rows_diff][7]\n",
    "                                vuams[row][14] = beat[5][row+rows_diff][8]\n",
    "                                vuams[row][15] = beat[5][row+rows_diff][9]\n",
    "                                vuams[row][16] = beat[5][row+rows_diff][10]\n",
    "                                vuams[row][17] = beat[5][row+rows_diff][11]\n",
    "                            except:\n",
    "                                pass\n",
    "                        elif vuams[markers][value_idx] == 265:\n",
    "                            try:\n",
    "                           \n",
    "                                vuams[row][7] = beat[6][row+rows_diff][1]\n",
    "                                vuams[row][8] = beat[6][row+rows_diff][2]\n",
    "                                vuams[row][9] = beat[6][row+rows_diff][3]\n",
    "                                vuams[row][10] = beat[6][row+rows_diff][4]\n",
    "                                vuams[row][11] = beat[6][row+rows_diff][5]\n",
    "                                vuams[row][12] = beat[6][row+rows_diff][6]\n",
    "                                vuams[row][13] = beat[6][row+rows_diff][7]\n",
    "                                vuams[row][14] = beat[6][row+rows_diff][8]\n",
    "                                vuams[row][15] = beat[6][row+rows_diff][9]\n",
    "                                vuams[row][16] = beat[6][row+rows_diff][10]\n",
    "                                vuams[row][17] = beat[6][row+rows_diff][11]\n",
    "                            except:\n",
    "                                pass\n",
    "                        elif vuams[markers][value_idx] == 275:\n",
    "                            try:\n",
    "                          \n",
    "                                vuams[row][7] = beat[7][row+rows_diff][1]\n",
    "                                vuams[row][8] = beat[7][row+rows_diff][2]\n",
    "                                vuams[row][9] = beat[7][row+rows_diff][3]\n",
    "                                vuams[row][10] = beat[7][row+rows_diff][4]\n",
    "                                vuams[row][11] = beat[7][row+rows_diff][5]\n",
    "                                vuams[row][12] = beat[7][row+rows_diff][6]\n",
    "                                vuams[row][13] = beat[7][row+rows_diff][7]\n",
    "                                vuams[row][14] = beat[7][row+rows_diff][8]\n",
    "                                vuams[row][15] = beat[7][row+rows_diff][9]\n",
    "                                vuams[row][16] = beat[7][row+rows_diff][10]\n",
    "                                vuams[row][17] = beat[7][row+rows_diff][11]\n",
    "                            except:\n",
    "                                pass\n",
    "            elif markers == start_markers[-1]:\n",
    "                for row in range(markers,markers + 150000): # m18 lasted two minutes so 150 seconds (30 seconds buffer)\n",
    "                    for value_idx in range(len(vuams[row])):\n",
    "                        if vuams[markers][value_idx] == 285:\n",
    "                            try:\n",
    "                                vuams[row][7] = beat[8][row+rows_diff][1]\n",
    "                                vuams[row][8] = beat[8][row+rows_diff][2]\n",
    "                                vuams[row][9] = beat[8][row+rows_diff][3]\n",
    "                                vuams[row][10] = beat[8][row+rows_diff][4]\n",
    "                                vuams[row][11] = beat[8][row+rows_diff][5]\n",
    "                                vuams[row][12] = beat[8][row+rows_diff][6]\n",
    "                                vuams[row][13] = beat[8][row+rows_diff][7]\n",
    "                                vuams[row][14] = beat[8][row+rows_diff][8]\n",
    "                                vuams[row][15] = beat[8][row+rows_diff][9]\n",
    "                                vuams[row][16] = beat[8][row+rows_diff][10]\n",
    "                                vuams[row][17] = beat[8][row+rows_diff][11]\n",
    "                            except:\n",
    "                                pass\n",
    "    merged_df = pd.DataFrame(vuams, columns =columns) # dataframe with merged information from bs\n",
    "    return merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36d68741-6d69-49cf-9f58-9b7a8ac44712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56 -numer osoby\n",
      "16:26:40.500\n",
      "check\n",
      "check2\n",
      "215\n",
      "782225\n",
      "8135\n",
      "225\n",
      "1281130\n",
      "8313\n",
      "235\n",
      "1782990\n",
      "8654\n",
      "245\n",
      "2292368\n",
      "8129\n",
      "255\n",
      "2787600\n",
      "7554\n",
      "265\n",
      "3269350\n",
      "22889\n",
      "275\n",
      "3745740\n",
      "8695\n",
      "285\n",
      "4234348\n",
      "8049\n",
      "check 3\n",
      "/home/ubuntu/eSportData/jupyter-data/akcelerometry/S2/S2_56.csv acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1560979/2072343602.py:211: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  acc['time'] = pd.to_datetime(acc['time'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['timestamp', 'ECG', 'DZ', 'DZDT', 'Z0', 'marker', 'SBP', 'DBP', 'MBP', 'HR', 'SV', 'LVET', 'PI', 'MS', 'CO', 'TPR', 'TPRCGS', 'marker_tx', 'dummy', 'wr', 'tl', 'tr']\n",
      "0.0\n",
      "nan\n",
      "check4\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "def S2_processing(root, path_tx, path_acc, rej, output_errors):\n",
    "    \"\"\"\n",
    "    main pipeline\n",
    "    input:\n",
    "        root: Main path to vuamsa files\n",
    "        path_tx: path to beatscope files\n",
    "        path_acc: path to accelerometers\n",
    "        rej = empty list for people who for some reason were not processed\n",
    "    output:\n",
    "        processed databases and list of people who were not processed by the pipeline\n",
    "    \"\"\"\n",
    "\n",
    "    with open(output_errors, 'w') as error_log:\n",
    "        for i in range(301):\n",
    "            # resetting variables and objects after each iteration\n",
    "            start_markers = []\n",
    "            txs = []\n",
    "            file_names = 0\n",
    "            subject_id = 0\n",
    "            txs = []\n",
    "            df_dz = pd.DataFrame()\n",
    "            df_ecg = pd.DataFrame()\n",
    "            df_z0 = pd.DataFrame()\n",
    "            acc_name = 0\n",
    "            ids = 0\n",
    "            tx_df = 0\n",
    "            file_path_tx = 0\n",
    "            da = pd.DataFrame()\n",
    "            da_bc = pd.DataFrame()\n",
    "            da_full = pd.DataFrame()\n",
    "            df_all = pd.DataFrame()\n",
    "            acc_sync_value = 0\n",
    "            trials = []\n",
    "            extended_txs = []\n",
    "            da_list = []\n",
    "            da_bc_list = []   \n",
    "            tx_last = 0\n",
    "            garry = pd.DataFrame()    \n",
    "            da_sync_idx = 0\n",
    "            da_sync_idx2 = 0\n",
    "            df_tx = pd.DataFrame()\n",
    "            acc = pd.DataFrame()\n",
    "            try:\n",
    "                bs_columns = ['timestamp', 'SBP', 'DBP', 'MBP', 'HR', 'SV', 'LVET', 'PI', 'MS', 'CO', 'TPR', 'TPRCGS', 'marker_tx', 'dummy']\n",
    "                da_bs_columns = ['timestamp_x', 'ECG','DZ' ,'DZDT','Z0', 'marker', 'timestamp_y', 'SBP', 'DBP', 'MBP', 'HR', 'SV', 'LVET', 'PI', 'MS', 'CO', 'TPR', 'TPRCGS', 'marker_tx','dummy']\n",
    "                col_names = ['timestamp','ECG', 'DZ', 'DZDT', 'Z0', 'marker']\n",
    "                markers_keys = {'201':'m10', '215':'m11', '225':'m12', '235':'m13', '245':'m14', '255':'m15', '265':'m16', '275':'m17', '285':'m18'}\n",
    "                ids = str(i) # identifier of the person whose files are being processed\n",
    "                print(ids, '- person number')\n",
    "                file_names = []\n",
    "                extended_txs = []\n",
    "                \n",
    "                for filename in os.listdir(root): # list of all files from paths\n",
    "                    \n",
    "                    if os.path.isfile(os.path.join(root, filename)):\n",
    "                        file_names.append(filename)\n",
    "                \n",
    "                for filename in os.listdir(path_tx):\n",
    "                    \n",
    "                    if os.path.isfile(os.path.join(path_tx, filename)):\n",
    "                        file_names.append(filename)\n",
    "                for filename in os.listdir(path_acc):\n",
    "                    \n",
    "                    if os.path.isfile(os.path.join(path_acc, filename)):\n",
    "                        file_names.append(filename)\n",
    "                \n",
    "                # create pattern based on identifier to include in the list only files with the numbers of interest   \n",
    "                pattern = fr'(?<![0-9m]){re.escape(ids)}(?![0-9])'\n",
    "                subject_id = [file_name for file_name in file_names if re.search(pattern, file_name)]\n",
    "                # patterns for vuams and acc files from the files selected for the given person based on the id containing appropriate keywords from the file names     \n",
    "                pattern_DZ = r'DZ[^A-Za-z]'\n",
    "                pattern_DZDT = r'DZDT'\n",
    "                pattern_ECG = r'ECG'\n",
    "                pattern_Z0 = r'Z0'\n",
    "                pattern_acc = fr'_{re.escape(ids)}'\n",
    "                # merging DA\n",
    "                for file_ in subject_id:\n",
    "                    # create dataframes from all vuams files\n",
    "                    if re.search(pattern_DZ, file_):\n",
    "                        file_path_dz = os.path.join('/home/ubuntu/eSportData/jupyter-data/VU_AMS/s2/', file_)\n",
    "                        df_dz = pd.read_csv(file_path_dz, sep=\" \", header=None, names=['index', 'DZ', 'marker1', 'marker2', 'dummy'], skiprows = 3)\n",
    "                        \n",
    "                    elif re.search(pattern_DZDT, file_):\n",
    "                        file_path_dzdt = os.path.join('/home/ubuntu/eSportData/jupyter-data/VU_AMS/s2/', file_)\n",
    "                        df_dzdt = pd.read_csv(file_path_dzdt, sep=\" \", header=None, names=['index', 'DZDT', 'marker1', 'marker2', 'dummy'], skiprows = 3)\n",
    "                    elif re.search(pattern_ECG, file_):\n",
    "                        file_path_ecg = os.path.join('/home/ubuntu/eSportData/jupyter-data/VU_AMS/s2/', file_)\n",
    "                        time =  extract_time_from_file(file_path_ecg) # read time from the ECG file using the function\n",
    "                        print(time)\n",
    "                        df_ecg = pd.read_csv(file_path_ecg, sep=\" \", header=None, names=['index', 'ECG', 'marker1', 'marker2', 'dummy'], skiprows = 3)\n",
    "                        \n",
    "                    elif re.search(pattern_Z0, file_): # also extending Z0 to 1000ms from 250\n",
    "                        file_path_z0 = os.path.join('/home/ubuntu/eSportData/jupyter-data/VU_AMS/s2/', file_)\n",
    "                        df_z0 = pd.read_csv(file_path_z0, sep=\" \", header=None, names=['index', 'Z0', 'marker1', 'marker2', 'dummy'], skiprows = 3)\n",
    "                        df_z0 = pd.concat([pd.DataFrame({'index': [df_z0['index'].min() - 1], 'Z0': [df_z0['Z0'].iloc[0]], 'marker1': [df_z0['marker1'].iloc[0]]}), df_z0])\n",
    "                        new_index = range(df_z0['index'].min(), df_z0['index'].max() + 1)\n",
    "                        df_z0 = df_z0.set_index('index').reindex(new_index)                    \n",
    "                        df_z0 = df_z0.ffill()\n",
    "                        df_z0 = df_z0.reset_index()\n",
    "                    elif re.search(pattern_acc, file_):\n",
    "                        acc_name = file_\n",
    "                ecg_col = df_ecg['ECG']\n",
    "                dz_col = df_dz['DZ']\n",
    "                dzdt_col = df_dzdt['DZDT']\n",
    "                z0_col = df_z0['Z0']\n",
    "                marker = df_ecg['marker2']\n",
    "                min_length = len(df_z0)\n",
    "                df_ecg = df_ecg.head(min_length)\n",
    "                df_dz = df_dz.head(min_length)\n",
    "                df_dzdt = df_dzdt.head(min_length)\n",
    "                data_dict = {'ECG': ecg_col, 'DZ': dz_col, 'DZDT': dzdt_col, 'Z0': z0_col, 'marker':marker}\n",
    "                da = pd.DataFrame(data_dict, index=df_dzdt.index, columns=col_names)\n",
    "                da.iloc[0,0] = time # append the read time to the empty column at the first position\n",
    "                da['timestamp'] = pd.to_datetime(da['timestamp'], format='%H:%M:%S.%f')\n",
    "                first_valid_index = 0\n",
    "                not_null_time = da.loc[first_valid_index, 'timestamp']\n",
    "                da_list = da.values.tolist()\n",
    "                for i in range(first_valid_index + 1, len(da_list)): # iterate over the entire set appending time 1 ms greater than the previous one, starting from the initially appended time\n",
    "                    not_null_time += timedelta(milliseconds=1)     # the operation is performed on the list instead of df to be faster\n",
    "                    da_list[i][0] = not_null_time\n",
    "                \n",
    "                da_full = pd.DataFrame(da_list, columns =col_names)\n",
    "                da_full['timestamp'] = da_full['timestamp'].dt.time\n",
    "                \n",
    "                pattern = fr'(?<![0-9m]){re.escape(ids)}(?![0-9])' # patterns for beatscope files\n",
    "                txs = [tx for tx in subject_id if re.search(r'_m', tx)]\n",
    "                txs.sort() # sort them in the list so I can freely iterate through them when adding them to the vuams df\n",
    "    \n",
    "                for tx in txs: # read and immediately extend to 1000ms\n",
    "                    file_path_tx = os.path.join('/home/ubuntu/eSportData/jupyter-data/beatscope/Pliki/S2', tx)\n",
    "                    tx_df = pd.read_csv(file_path_tx, sep=';', header=None, skiprows=10, encoding='cp1250', decimal=',', names=bs_columns)     \n",
    "                    tx_df['timestamp'] = pd.to_datetime(tx_df['timestamp'], format='%H:%M:%S,%f')\n",
    "                    tx_df = tx_df.set_index('timestamp')\n",
    "                    tx_df = tx_df.resample('ms').ffill()\n",
    "                    tx_df = tx_df.reset_index()\n",
    "                    tx_df['timestamp'] = tx_df['timestamp'].dt.time\n",
    "                    extended_txs.append(tx_df)      \n",
    "                    extended_txs[-1].iloc[extended_txs[-1].index.max(), -2] = 'End' # add \"end\" designation for the last beatscope in the last row to know where to cut if needed\n",
    "                da_sync_idx = da_full.index[da_full['marker'] != -9999][0] - 240000 # place of marker occurrence - 4 minutes, because for some reason for the baseline markers did not appear at the beginning but after 4 minutes\n",
    "                da_sync_idx2 = da_full.index[da_full['marker'] != -9999][0] # place of marker start (incorrect)\n",
    "                for i in range(da_sync_idx, da_sync_idx2): # fill the empty space where markers 201 should be\n",
    "                    da_full.iloc[i, 5] = 201\n",
    "                \n",
    "                garry = extended_txs[0]\n",
    "                tx_sync_idx = garry.index[garry['marker_tx'].notna()][0] # find marker from the first bs\n",
    "                            \n",
    "                assert garry.at[tx_sync_idx, 'marker_tx'].startswith('m')             \n",
    "                rows_diff = tx_sync_idx - da_sync_idx\n",
    "                if rows_diff > 0:  # \n",
    "                    garry = garry.iloc[rows_diff:]\n",
    "                    garry = garry.reset_index(drop=True)\n",
    "                else:\n",
    "                    da_full = da_full.iloc[-rows_diff:] # cut vuams df so that the vuams marker appears in the same place as the bs marker\n",
    "                    da_full = da_full.reset_index(drop=True) \n",
    "                garry = garry.rename(columns = {'timestamp': 'timestamp_y'})\n",
    "                da_bc = da_full.merge(garry, how='left', left_index=True, right_index=True) # merge vuams with bs\n",
    "                time_col = da_full['timestamp'] # extract time column from vuams\n",
    "                \n",
    "                trials = [pd.merge(time_col, tx, on='timestamp', how='left') for tx in extended_txs] # new list of beatscopes, with time added from vuams\n",
    "                txs_list = [trial.values.tolist() for trial in trials]\n",
    "                da_bc_list = da_bc.values.tolist()\n",
    "                start_0 = da_bc.index[da_bc['marker'] ==201][0]\n",
    "                start_1 = da_bc.index[da_bc['marker'] ==215][0]\n",
    "                start_2 = da_bc.index[da_bc['marker'] == 225][0]\n",
    "                start_3 = da_bc.index[da_bc['marker'] == 235][0]\n",
    "                start_4 = da_bc.index[da_bc['marker'] == 245][0]\n",
    "                start_5 = da_bc.index[da_bc['marker'] == 255][0]\n",
    "                start_6 = da_bc.index[da_bc['marker'] == 265][0]\n",
    "                start_7 = da_bc.index[da_bc['marker'] == 275][0]\n",
    "                start_8 = da_bc.index[da_bc['marker'] == 285][0]\n",
    "                start_markers = [start_0, start_1, start_2, start_3, start_4, start_5, start_6, start_7, start_8] # list of starting indexes for all markers from vuams\n",
    "                df_tx = merge_vs_tx(start_markers, da_bc_list, txs_list, da_bs_columns, da_bc, trials, markers_keys) # assign a new dataframe from the merged function to combine vuams with bs                \n",
    "                # processing accelerometers\n",
    "                try:\n",
    "                    file_path_acc = os.path.join('/home/ubuntu/eSportData/jupyter-data/akcelerometry/S2', acc_name)\n",
    "                    acc = pd.read_csv(file_path_acc, header=None, sep=';', encoding='cp1250', decimal=',', names = ['time', 'wr', 'tl', 'tr', '1', '2', '3'], usecols = ['time', 'wr', 'tl', 'tr'], skiprows = 11)\n",
    "                    print(file_path_acc, 'acc')\n",
    "                    \n",
    "                    acc = acc.iloc[:-4]\n",
    "                    # extending acc to 1000ms\n",
    "                    acc['time'] = acc['time'].astype(str)\n",
    "                    acc['time'] = pd.to_datetime(acc['time'])\n",
    "                    \n",
    "                    acc['timestamp'] = acc['time'].apply(lambda x: x + timedelta(microseconds=1000))\n",
    "                    acc = acc.iloc[:-2]\n",
    "                    acc['timestamp'] = pd.to_datetime(acc['timestamp'], format='%H:%M:%S.%f')\n",
    "                    acc = acc.set_index('timestamp')\n",
    "                    acc = acc.resample('ms').ffill()\n",
    "                    acc = acc.reset_index()\n",
    "                    acc['timestamp'] = acc['timestamp'].dt.time\n",
    "                    acc = acc.drop(columns = ['time'])\n",
    "                    acc_sync_value = df_tx.iloc[0,0] # cut acc df to the dimensions of the df with the combined vuams and bs\n",
    "                    acc_sync_idx = acc['timestamp'].index[acc['timestamp'] == acc_sync_value][0]\n",
    "                    try:\n",
    "                        acc_last_value = df_tx.iloc[-1,0]\n",
    "                        acc_last_idx = acc['timestamp'].index[acc['timestamp'] == acc_last_value][0]\n",
    "                        acc = acc.iloc[acc_sync_idx: acc_last_idx]\n",
    "                        acc = acc.reset_index(drop=True)\n",
    "                    except:\n",
    "                        pass\n",
    "                    df_tx = df_tx.drop(columns = ['timestamp_y'], axis = 1)\n",
    "                    df_tx = df_tx.rename(columns={'timestamp_x': 'timestamp'})\n",
    "                    df_all = df_tx.merge(acc, how='left', on = 'timestamp') # merge acc with vuams and bs to get everything together\n",
    "                except:\n",
    "                    df_tx['wr'] = -9999\n",
    "                    df_tx['tl'] = -9999\n",
    "                    df_tx['tr'] = -9999\n",
    "                    df_tx = df_tx.drop(columns = ['timestamp_y'], axis = 1)\n",
    "                    df_tx = df_tx.rename(columns={'timestamp_x': 'timestamp'})\n",
    "                    df_all = df_tx\n",
    "                print(list(df_all.columns))\n",
    "                df_all['marker_y'] = df_all['marker']\n",
    "                df_all = df_all.drop(columns = ['dummy','marker', 'marker_tx'], axis = 1) # drop all unnecessary columns and change their name\n",
    "                df_all = df_all.rename(columns={'marker_y': 'marker'})\n",
    "                df_all = df_all.iloc[:-2]\n",
    "                print(df_all.iloc[0, -2])\n",
    "                print(df_all.iloc[-1, -2])\n",
    "                print('done')\n",
    "                \n",
    "                df_all.to_csv(f'/home/ubuntu/eSportData/jupyter-data/VU_AMS/s2_output/S2_p{ids}.csv', index=False) # save using id\n",
    "            except Exception as e:\n",
    "                error_message = f\"Error processing ID {id}: {str(e)}\"\n",
    "                print(error_message, file=error_log)\n",
    "    \n",
    "    return rej\n",
    "error_file = S2_processing(path, path_tx, path_acc, rejected, output_errors_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0477018-fdd5-40f1-b212-71c051d84e65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['               total        used        free      shared  buff/cache   available',\n",
       " 'Mem:           96550         504       95762           1         283       95260',\n",
       " 'Swap:              0           0           0']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%system free -m"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
